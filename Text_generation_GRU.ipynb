{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r0cSJEO-mZN"
      },
      "source": [
        "# Setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5goJHa0q-mns"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OANmVha3_ccg"
      },
      "source": [
        "# Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "59SmGp8X_Cyo"
      },
      "outputs": [],
      "source": [
        "path_to_file = \"./aud_data.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cF9aBLE_LY-",
        "outputId": "295cdbfa-6714-42d6-df92-b86b21279e85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 978138 characters\n"
          ]
        }
      ],
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDZf5-RP_Tah",
        "outputId": "8bc316da-8722-41d1-859c-68b50122f720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IsTVfqp4OxHm",
        "outputId": "79786c0a-8940-4a89-b55a-cc68609113cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'လူတိုင်း မှာ မ ရှိ သင့် တဲ့ အရာ က မနာလိုစိတ် ပဲ ဖြစ် တယ်\\nမနာလိုစိတ် ဆိုတာ ဘယ်သူ့ ကို မှ ကောင်းကျိုး မ ပေး ဘူး\\nတခြား သူ ကို မနာလို တဲ့ အခါ သူ ဟာ အသုံးမကျ တဲ့ လူ ဖြစ် သွား တတ် တယ်\\nကိုယ့် ပြိုင်ဘက် အတွက်'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "text[0:200]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j6JgZ-o_ZCw"
      },
      "source": [
        "# Process the text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSGBC-G6_l8A"
      },
      "source": [
        "## Vectorize the text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqxkJuMRBCJx"
      },
      "source": [
        "Before training, you need to convert the strings to a numerical representation.\n",
        "\n",
        "The tf.keras.layers.StringLookup layer can convert each character into a numeric ID. It just needs the text to be split into tokens first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wuFbOlw4_leW"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)\n",
        "chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ_jZxk6Bpp_"
      },
      "source": [
        "# Create training examples and targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "alHt7udsBWvJ"
      },
      "outputs": [],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKJaOSuKFNvR",
        "outputId": "4a89ef54-3ec0-4e77-ec0a-2d139d338528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "လ\n",
            "ူ\n",
            "တ\n",
            "ိ\n",
            "ု\n",
            "င\n",
            "်\n",
            "း\n",
            " \n",
            "မ\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FpS3gEqNFWx-"
      },
      "outputs": [],
      "source": [
        "seq_length = 200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRDNNgjzF4Ii"
      },
      "source": [
        "The batch method lets you easily convert these individual characters to sequences of the desired size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c69F8SGpFy65"
      },
      "outputs": [],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKrlDP2aGeXW"
      },
      "source": [
        "For training you'll need a dataset of (input, label) pairs. Where input and label are sequences. At each time step the input is the current character and the label is the next character."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "re5UR357GPV2"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6zapQTM4GoKX"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BtZRNHVHkQx"
      },
      "source": [
        "# Create training batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zckZdezXHpDa"
      },
      "source": [
        "Use tf.data to split the text into manageable sequences\n",
        "\n",
        "But before feeding this data into the model, it is needed to shuffle the data and pack it into batches.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi784txVHdou",
        "outputId": "a19a1daf-63da-4711-f8e6-f642f89aac97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 200), dtype=tf.int64, name=None), TensorSpec(shape=(64, 200), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE =  64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7AvOF4DIbJO"
      },
      "source": [
        "# Build The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49aJTMHTIlYT"
      },
      "source": [
        "This model has three layers:\n",
        "\n",
        "tf.keras.layers.Embedding: The input layer. A trainable lookup table that will map each character-ID to a vector with embedding_dim dimensions;\n",
        "\n",
        "tf.keras.layers.GRU: A type of RNN with size units=rnn_units\n",
        "\n",
        "tf.keras.layers.Dense: The output layer, with vocab_size outputs. It outputs one logit for each character in the vocabulary. These are the log-likelihood of each character according to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PrURP-dZIakA"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wWwm9CNAKXJj"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Z1TtT8bnI-O5"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgawboWEKo4b",
        "outputId": "162dc0be-49e9-4871-a74d-f05a59b97fd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 200, 67) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF8_1J3gJ_BK",
        "outputId": "3eb05858-f8e0-45c5-f72f-8fc9edc820f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  17152     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  68675     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4024131 (15.35 MB)\n",
            "Trainable params: 4024131 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6nHohXjI_bq"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ldNgia8sLNhO"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UG4tjA8bLXbG"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n",
        "EPOCHS = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTw1s0KFLa3N",
        "outputId": "f5de5caa-6a3e-44fb-81aa-3678a06fffbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "76/76 [==============================] - 14s 107ms/step - loss: 2.9680\n",
            "Epoch 2/100\n",
            "76/76 [==============================] - 11s 114ms/step - loss: 1.8786\n",
            "Epoch 3/100\n",
            "76/76 [==============================] - 10s 106ms/step - loss: 1.6708\n",
            "Epoch 4/100\n",
            "76/76 [==============================] - 10s 108ms/step - loss: 1.5170\n",
            "Epoch 5/100\n",
            "76/76 [==============================] - 10s 109ms/step - loss: 1.3984\n",
            "Epoch 6/100\n",
            "76/76 [==============================] - 11s 110ms/step - loss: 1.3058\n",
            "Epoch 7/100\n",
            "76/76 [==============================] - 10s 111ms/step - loss: 1.2338\n",
            "Epoch 8/100\n",
            "76/76 [==============================] - 11s 115ms/step - loss: 1.1787\n",
            "Epoch 9/100\n",
            "76/76 [==============================] - 10s 116ms/step - loss: 1.1344\n",
            "Epoch 10/100\n",
            "76/76 [==============================] - 10s 118ms/step - loss: 1.0960\n",
            "Epoch 11/100\n",
            "76/76 [==============================] - 10s 118ms/step - loss: 1.0637\n",
            "Epoch 12/100\n",
            "76/76 [==============================] - 10s 113ms/step - loss: 1.0348\n",
            "Epoch 13/100\n",
            "76/76 [==============================] - 10s 114ms/step - loss: 1.0070\n",
            "Epoch 14/100\n",
            "76/76 [==============================] - 10s 117ms/step - loss: 0.9815\n",
            "Epoch 15/100\n",
            "76/76 [==============================] - 12s 123ms/step - loss: 0.9571\n",
            "Epoch 16/100\n",
            "76/76 [==============================] - 11s 116ms/step - loss: 0.9322\n",
            "Epoch 17/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.9087\n",
            "Epoch 18/100\n",
            "76/76 [==============================] - 10s 114ms/step - loss: 0.8849\n",
            "Epoch 19/100\n",
            "76/76 [==============================] - 11s 113ms/step - loss: 0.8604\n",
            "Epoch 20/100\n",
            "76/76 [==============================] - 10s 114ms/step - loss: 0.8336\n",
            "Epoch 21/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.8085\n",
            "Epoch 22/100\n",
            "76/76 [==============================] - 10s 117ms/step - loss: 0.7819\n",
            "Epoch 23/100\n",
            "76/76 [==============================] - 11s 116ms/step - loss: 0.7540\n",
            "Epoch 24/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.7252\n",
            "Epoch 25/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.6956\n",
            "Epoch 26/100\n",
            "76/76 [==============================] - 10s 114ms/step - loss: 0.6656\n",
            "Epoch 27/100\n",
            "76/76 [==============================] - 11s 114ms/step - loss: 0.6343\n",
            "Epoch 28/100\n",
            "76/76 [==============================] - 10s 113ms/step - loss: 0.6057\n",
            "Epoch 29/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.5748\n",
            "Epoch 30/100\n",
            "76/76 [==============================] - 11s 117ms/step - loss: 0.5462\n",
            "Epoch 31/100\n",
            "76/76 [==============================] - 11s 119ms/step - loss: 0.5168\n",
            "Epoch 32/100\n",
            "76/76 [==============================] - 10s 116ms/step - loss: 0.4891\n",
            "Epoch 33/100\n",
            "76/76 [==============================] - 10s 114ms/step - loss: 0.4646\n",
            "Epoch 34/100\n",
            "76/76 [==============================] - 11s 113ms/step - loss: 0.4414\n",
            "Epoch 35/100\n",
            "76/76 [==============================] - 10s 114ms/step - loss: 0.4184\n",
            "Epoch 36/100\n",
            "76/76 [==============================] - 10s 114ms/step - loss: 0.3999\n",
            "Epoch 37/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.3818\n",
            "Epoch 38/100\n",
            "76/76 [==============================] - 11s 115ms/step - loss: 0.3648\n",
            "Epoch 39/100\n",
            "76/76 [==============================] - 10s 113ms/step - loss: 0.3516\n",
            "Epoch 40/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.3385\n",
            "Epoch 41/100\n",
            "76/76 [==============================] - 11s 118ms/step - loss: 0.3277\n",
            "Epoch 42/100\n",
            "76/76 [==============================] - 10s 116ms/step - loss: 0.3159\n",
            "Epoch 43/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.3055\n",
            "Epoch 44/100\n",
            "76/76 [==============================] - 10s 111ms/step - loss: 0.2961\n",
            "Epoch 45/100\n",
            "76/76 [==============================] - 11s 114ms/step - loss: 0.2882\n",
            "Epoch 46/100\n",
            "76/76 [==============================] - 10s 116ms/step - loss: 0.2825\n",
            "Epoch 47/100\n",
            "76/76 [==============================] - 10s 121ms/step - loss: 0.2765\n",
            "Epoch 48/100\n",
            "76/76 [==============================] - 11s 117ms/step - loss: 0.2722\n",
            "Epoch 49/100\n",
            "76/76 [==============================] - 10s 116ms/step - loss: 0.2647\n",
            "Epoch 50/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.2575\n",
            "Epoch 51/100\n",
            "76/76 [==============================] - 10s 113ms/step - loss: 0.2557\n",
            "Epoch 52/100\n",
            "76/76 [==============================] - 11s 113ms/step - loss: 0.2512\n",
            "Epoch 53/100\n",
            "76/76 [==============================] - 10s 114ms/step - loss: 0.2431\n",
            "Epoch 54/100\n",
            "76/76 [==============================] - 10s 116ms/step - loss: 0.2386\n",
            "Epoch 55/100\n",
            "76/76 [==============================] - 10s 117ms/step - loss: 0.2349\n",
            "Epoch 56/100\n",
            "76/76 [==============================] - 11s 115ms/step - loss: 0.2375\n",
            "Epoch 57/100\n",
            "76/76 [==============================] - 10s 112ms/step - loss: 0.2335\n",
            "Epoch 58/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.2327\n",
            "Epoch 59/100\n",
            "76/76 [==============================] - 11s 117ms/step - loss: 0.2299\n",
            "Epoch 60/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.2282\n",
            "Epoch 61/100\n",
            "76/76 [==============================] - 10s 117ms/step - loss: 0.2263\n",
            "Epoch 62/100\n",
            "76/76 [==============================] - 10s 118ms/step - loss: 0.2282\n",
            "Epoch 63/100\n",
            "76/76 [==============================] - 10s 112ms/step - loss: 0.2249\n",
            "Epoch 64/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.2208\n",
            "Epoch 65/100\n",
            "76/76 [==============================] - 10s 117ms/step - loss: 0.2187\n",
            "Epoch 66/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.2161\n",
            "Epoch 67/100\n",
            "76/76 [==============================] - 10s 116ms/step - loss: 0.2166\n",
            "Epoch 68/100\n",
            "76/76 [==============================] - 10s 119ms/step - loss: 0.2146\n",
            "Epoch 69/100\n",
            "76/76 [==============================] - 10s 112ms/step - loss: 0.2155\n",
            "Epoch 70/100\n",
            "76/76 [==============================] - 10s 114ms/step - loss: 0.2124\n",
            "Epoch 71/100\n",
            "76/76 [==============================] - 10s 118ms/step - loss: 0.2120\n",
            "Epoch 72/100\n",
            "76/76 [==============================] - 10s 113ms/step - loss: 0.2148\n",
            "Epoch 73/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.2160\n",
            "Epoch 74/100\n",
            "76/76 [==============================] - 10s 118ms/step - loss: 0.2136\n",
            "Epoch 75/100\n",
            "76/76 [==============================] - 11s 117ms/step - loss: 0.2122\n",
            "Epoch 76/100\n",
            "76/76 [==============================] - 10s 116ms/step - loss: 0.2056\n",
            "Epoch 77/100\n",
            "76/76 [==============================] - 10s 113ms/step - loss: 0.2013\n",
            "Epoch 78/100\n",
            "76/76 [==============================] - 10s 113ms/step - loss: 0.1967\n",
            "Epoch 79/100\n",
            "76/76 [==============================] - 11s 117ms/step - loss: 0.1919\n",
            "Epoch 80/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.1937\n",
            "Epoch 81/100\n",
            "76/76 [==============================] - 10s 117ms/step - loss: 0.1965\n",
            "Epoch 82/100\n",
            "76/76 [==============================] - 11s 117ms/step - loss: 0.2003\n",
            "Epoch 83/100\n",
            "76/76 [==============================] - 10s 114ms/step - loss: 0.2039\n",
            "Epoch 84/100\n",
            "76/76 [==============================] - 10s 113ms/step - loss: 0.2066\n",
            "Epoch 85/100\n",
            "76/76 [==============================] - 10s 114ms/step - loss: 0.2105\n",
            "Epoch 86/100\n",
            "76/76 [==============================] - 11s 113ms/step - loss: 0.2195\n",
            "Epoch 87/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.2185\n",
            "Epoch 88/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.2185\n",
            "Epoch 89/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.2158\n",
            "Epoch 90/100\n",
            "76/76 [==============================] - 11s 114ms/step - loss: 0.2149\n",
            "Epoch 91/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.2116\n",
            "Epoch 92/100\n",
            "76/76 [==============================] - 10s 114ms/step - loss: 0.2062\n",
            "Epoch 93/100\n",
            "76/76 [==============================] - 11s 113ms/step - loss: 0.2020\n",
            "Epoch 94/100\n",
            "76/76 [==============================] - 10s 115ms/step - loss: 0.1985\n",
            "Epoch 95/100\n",
            "76/76 [==============================] - 10s 118ms/step - loss: 0.1981\n",
            "Epoch 96/100\n",
            "76/76 [==============================] - 10s 119ms/step - loss: 0.1926\n",
            "Epoch 97/100\n",
            "76/76 [==============================] - 11s 115ms/step - loss: 0.1936\n",
            "Epoch 98/100\n",
            "76/76 [==============================] - 10s 112ms/step - loss: 0.1898\n",
            "Epoch 99/100\n",
            "76/76 [==============================] - 10s 113ms/step - loss: 0.1894\n",
            "Epoch 100/100\n",
            "76/76 [==============================] - 11s 116ms/step - loss: 0.1913\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3HuRbGXOMMd"
      },
      "source": [
        "# Generate text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ja2cfaYONRf"
      },
      "source": [
        "The simplest way to generate text with this model is to run it in a loop, and keep track of the model's internal state as you execute it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udO5OK_nPMys",
        "outputId": "4c345641-ea89-4a2f-805b-fedaeb176dba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f31b1d6ce50>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "model = MyModel(vocab_size, embedding_dim, rnn_units)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "mMrPA8FROQiE"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "c2vD0Bj9PKcK"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars,1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovoWq4LhP2Fg",
        "outputId": "990920d2-1dbb-4acf-d48e-eac12572bcbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "နေကောင်း ကြ တာ ပဲ\n",
            " \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 0.9716076850891113\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def generate_text_until_sentences(model, initial_text, num_sentences=1, max_length=100):\n",
        "    start = time.time()\n",
        "    states = None\n",
        "    next_char = tf.constant([initial_text])\n",
        "    result = [next_char]\n",
        "\n",
        "    sentence_count = 0\n",
        "\n",
        "    while sentence_count < num_sentences:\n",
        "        next_char, states = model.generate_one_step(next_char, states=states)\n",
        "        result.append(next_char)\n",
        "\n",
        "        # Check if the generated character is the end of a sentence\n",
        "        generated_text = next_char[0].numpy().decode('utf-8')\n",
        "        if generated_text and generated_text[-1] in ['\\n']:\n",
        "            sentence_count += 1\n",
        "\n",
        "        # Limit the length of the generated text\n",
        "        if len(result) >= max_length:\n",
        "            break\n",
        "\n",
        "    result = tf.strings.join(result)\n",
        "    end = time.time()\n",
        "    print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "    print('\\nRun time:', end - start)\n",
        "\n",
        "generate_text_until_sentences(one_step_model, 'နေကောင်း ကြ ', num_sentences=1, max_length=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzU0Qw1ls0wz",
        "outputId": "ae6e2b6b-4963-4e8f-aa0b-8a15158c3c3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "အဆင်ပြေ ကြ တယ် ပေါ့\n",
            " \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 0.021728515625\n"
          ]
        }
      ],
      "source": [
        "generate_text_until_sentences(one_step_model, 'အဆင်ပြေ ကြ တယ် ', num_sentences=1, max_length=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltM7mUbLStB1",
        "outputId": "200f8c79-7d1d-4c98-ec2c-78558505c582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "နံပါတ် တစ် က ကို ကောင်း တယ်\n",
            " \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 0.07864689826965332\n"
          ]
        }
      ],
      "source": [
        "generate_text_until_sentences(one_step_model, 'နံပါတ် တစ် ', num_sentences=1, max_length=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBt7zgz1TSzw",
        "outputId": "64e0eb6b-0034-4fd8-b727-3197cbf72b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "သာမာန် လူ တွေ က မျက်လုံး နှစ်လုံး ဖွင့် ပြီး တော့ သူ့ ကို ဂရုစိုက် ခြင်း တွေ ရှိ တယ်\n",
            " \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 0.12487626075744629\n"
          ]
        }
      ],
      "source": [
        "generate_text_until_sentences(one_step_model, 'သာမာန် လူ တွေ က မျက်လုံး နှစ်လုံး ဖွင့် ပြီး ', num_sentences=1, max_length=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA9niAVhTldY",
        "outputId": "1e0c814d-ae2d-4730-81d6-fbae8fdac8a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "အောင်မြင်ခြင်း နဲ့ ကျရှုံးခြင်း တွေ ရဲ့ ကြား မှာ မ ဖြစ် နိုင် တဲ့ စည်း တွေ ဖယ် ပေး သော အသက်အရွယ် တွေ ကို တာဝန် သိ စွာ တွဲ နေ ခဲ့ မှာ ပဲ\n",
            " \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 0.1983342170715332\n"
          ]
        }
      ],
      "source": [
        "generate_text_until_sentences(one_step_model, 'အောင်မြင်ခြင်း နဲ့ ကျရှုံးခြင်း တွေ ရဲ့ ကြား မှာ မ ဖြစ် နိုင် တဲ့ စည်း တွေ ', num_sentences=1, max_length=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu-GnsKSTy7p",
        "outputId": "00505dd3-e36a-4707-f185-8ac49738b001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "မင်း ဘာ ကြောင့် အောင်မြင် မှု ရ သည် အကြောင်း ကျွမ်းကျပ် အရှုံး တွေ ကို ဝါသနာ တွေ အများကြီး မ ကြိုးစား ခဲ့ စေ ချင် ဘူး\n",
            " \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 0.29592370986938477\n"
          ]
        }
      ],
      "source": [
        "generate_text_until_sentences(one_step_model, 'မင်း ဘာ ကြောင့် အောင်မြင် ', num_sentences=1, max_length=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "M-kT6x2yZhpl"
      },
      "outputs": [],
      "source": [
        "# update temperature\n",
        "one_step_model_upd = OneStep(model, chars_from_ids, ids_from_chars,0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR-F6nihZrMo",
        "outputId": "c27d524d-42df-46d9-ef51-5eb473e80a96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "နေကောင်း ကြ တော့ တယ်\n",
            " \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 0.9389612674713135\n"
          ]
        }
      ],
      "source": [
        "generate_text_until_sentences(one_step_model_upd, 'နေကောင်း ကြ ', num_sentences=1, max_length=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmj-Hpn9Zwhc",
        "outputId": "f5aad692-9c98-48f2-944c-8114e343339b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "အဆင်ပြေ ကြ တယ် ပေါ့\n",
            " \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 0.022274255752563477\n"
          ]
        }
      ],
      "source": [
        "generate_text_until_sentences(one_step_model_upd, 'အဆင်ပြေ ကြ တယ် ', num_sentences=1, max_length=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueX7J_HwZzIk",
        "outputId": "7359504a-fc96-4632-8c4b-6601ac1c97aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "နံပါတ် တစ် က ကြာ တယ် လေ\n",
            " \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 0.04493832588195801\n"
          ]
        }
      ],
      "source": [
        "generate_text_until_sentences(one_step_model_upd, 'နံပါတ် တစ် ', num_sentences=1, max_length=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4YgDUqwZ3DV",
        "outputId": "ba8598a3-397a-43da-8bd5-cb019d79a317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "သာမာန် လူ တွေ က မျက်လုံး နှစ်လုံး ဖွင့် ပြီး လောကကြီး ကို ကြည့် တယ်\n",
            " \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 0.1061711311340332\n"
          ]
        }
      ],
      "source": [
        "generate_text_until_sentences(one_step_model_upd, 'သာမာန် လူ တွေ က မျက်လုံး နှစ်လုံး ဖွင့် ပြီး ', num_sentences=1, max_length=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3fOmDq8Z6pb",
        "outputId": "6139b890-2e34-4a69-c1e7-86596dcd52c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "အောင်မြင်ခြင်း နဲ့ ကျရှုံးခြင်း တွေ ရဲ့ ကြား မှာ မ ဖြစ် နိုင် တဲ့ စည်း တွေ ခြား မ ထား ဘူး\n",
            " \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 0.0512235164642334\n"
          ]
        }
      ],
      "source": [
        "generate_text_until_sentences(one_step_model_upd, 'အောင်မြင်ခြင်း နဲ့ ကျရှုံးခြင်း တွေ ရဲ့ ကြား မှာ မ ဖြစ် နိုင် တဲ့ စည်း တွေ ', num_sentences=1, max_length=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERlO_bw7Z-Hf",
        "outputId": "5165083c-1027-4e83-b1d3-74969504f557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "မင်း ဘာ ကြောင့် အောင်မြင် ဖို့ အတွက် အခွင့်အရေး ရှိ လာ မှာ ပါ\n",
            " \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 0.10771512985229492\n"
          ]
        }
      ],
      "source": [
        "generate_text_until_sentences(one_step_model_upd, 'မင်း ဘာ ကြောင့် အောင်မြင် ', num_sentences=1, max_length=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR3_UocG_nlC"
      },
      "source": [
        "# Export the Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPgfJvy1_nBA",
        "outputId": "06417291-5ae1-4047-c07e-8466b6c61c64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f31b16d3040>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(one_step_model_upd, 'one_step')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aIXcynuy98z",
        "outputId": "2ebd9a6b-1128-4654-ddc2-e39925181704"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv training_checkpoints /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "rfHLWv21zPoj"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv one_step /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "2A2vssmgzUss"
      },
      "execution_count": 45,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}